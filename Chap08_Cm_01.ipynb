{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMslurSPpnq5Pxm5ScXZyeS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HinaNitano/EU_M_Math/blob/main/Chap08_Cm_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 総合問題8-1"
      ],
      "metadata": {
        "id": "C2fYyj119rPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**回帰：**\n",
        "連続的な値を予測するための手法であり、例えば住宅価格の予測などに使用される。(1)\n",
        "\n",
        "**分類：**\n",
        "カテゴリやクラスに対する予測を行う手法であり、例えばスパムメールの分類などに使用される。(1)\n",
        "\n",
        "**教師あり学習：**\n",
        "機械学習の一種で、コンピューターに対してラベルと呼ばれる正解データを提供することで学習させる手法である。つまり、人が用意した既知のデータとそのデータに対する正解をコンピューターに与えることで、コンピューターがデータの特徴やパターンを学習し、未知のデータに対して予測や分類を行えるようになる。(1)\n",
        "\n",
        "**重回帰分析：**\n",
        "重回帰分析とは、回帰分析のうち、説明変数が複数あるものを指す。\n",
        "たとえば、小売店で売上に影響する要素には、立地（駅からの距離など）、売り場面積、商品数などさまざまなものがある。こうした要素のうち、どれがどれだけ大きな影響を与えているのかを分析できるのが重回帰分析である。(2)\n",
        "\n",
        "**ロジスティクス回帰分析：**\n",
        "複数の説明変数から「Yes/No」「合格/不合格」のように答えが2つしかない値の目的変数の確率を説明・予測する。(2)\n",
        "\n",
        "**正則化：**\n",
        "過学習を起こすとそれぞれの標準偏回帰係数の絶対値が非常に大きくなる。傾きが大きいと曲線の波が細かく、大きくなるイメージだ。\n",
        "これを防ぐために損失関数に標準偏回帰係数の大きさを表す項を入れる。これを正則化項と呼ぶ。(3)\n",
        "\n",
        "**リッジ回帰：**\n",
        "大きな特徴量にペナルティーを与えて重みを調整し、過学習を回避するために用いる。(4)\n",
        "\n",
        "**ラッソ回帰：**\n",
        "特徴量が多い。過学習を防いだりモデルをシンプルにしたりする際に不要なパラメータを削るために用いる。(4)\n",
        "\n",
        "**決定木：**\n",
        "分類木と回帰木を組み合わせたもので、ツリー（樹形図）によってデータを分析する手法である。(5)\n",
        "\n",
        "**エントロピー：**\n",
        "機械学習で分類を行うモデルを作成した後に、予測値と実際の値との誤差を見るための関数である。(6)\n",
        "\n",
        "**情報利得：**\n",
        "ある変数を使ってデータを分割するとき、そのデータ分割前後でどれだけエントロピーが減少したかを表す指標である。\n",
        "\n",
        "**k-NN法：**\n",
        "データをグループ分けするにあたり、対象とするあるデータがどのグループに含まれるかを周囲のデータの多数決で推測するという手法である。(7)\n",
        "\n",
        "**SVM：**\n",
        "2つのクラスのデータ群を分割するような境界線や超平面を決定することで分類や回帰を行う手法。(8)\n",
        "\n",
        "**ノーフリーランチ：**\n",
        "あらゆる問題を効率よく解けるような“万能”の「教師ありの機械学習モデル」や「探索／最適化のアルゴリズム」などは存在しない（理論上、実現不可能）、ということを主張する定理である。(9)"
      ],
      "metadata": {
        "id": "L17SS4K69xnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**参考文献：**\n",
        "\n",
        "（1）「教師あり学習」　ソフトバンク　AI用語集\n",
        "\n",
        "URL：https://www.softbank.jp/biz/solutions/generative-ai/ai-glossary/supervised-learning/\n",
        "\n",
        "\n",
        "（2）「重回帰分析とは？　～目的から手順や注意点までわかりやすく解説～」　IM-Prees (2023/03/31)\n",
        "\n",
        "URL：https://www.intra-mart.jp/im-press/useful/multi-regression_analysis\n",
        "\n",
        "（3）「線形回帰の過学習を抑えよう ～Ridge回帰とLasso回帰～」　Nature Insight\n",
        "\n",
        "URL：https://www.n-insight.co.jp/niblog/20190917-1351/\n",
        "\n",
        "（4）「ラッソ回帰とリッジ回帰の理論」　Qitta　（2021年09月10日）\n",
        "\n",
        "URL：https://qiita.com/oki_kosuke/items/fb8bb418167f2ab1744e\n",
        "\n",
        "（5）「決定木分析（ディシジョンツリー）とは？概要や活用方法、ランダムフォレストも解説」　Cacoo　（2020年4月14日）\n",
        "\n",
        "URL：https://cacoo.com/ja/blog/what-is-decision-tree/\n",
        "\n",
        "（6）「交差エントロピーとは？誤差の計算からPythonでの実装まで解説」 サルでもわかるデータサイエンス　（2024年1月15日）\n",
        "\n",
        "URL：https://shoblog.iiyan.net/cross-entropy/#st-toc-h-1\n",
        "\n",
        "（7）「k近傍法（knn）をわかりやすく Python を用いて基本から実装まで解説」　zero one　（2023.8.4）\n",
        "\n",
        "URL：https://zero2one.jp/learningblog/k-nearest-neighbor-python/\n",
        "\n",
        "（8）「サポートベクターマシン (SVM)」　zero one\n",
        "\n",
        "URL：https://zero2one.jp/ai-word/support-vector-machine/\n",
        "\n",
        "（9）「ノーフリーランチ定理（No Free Lunch theorem）とは？」　AI・機械学習の用語辞典　@IT　（2020年07月17日）\n",
        "\n",
        "URL：https://atmarkit.itmedia.co.jp/ait/articles/2007/17/news020.html"
      ],
      "metadata": {
        "id": "kq32eL3DIsYv"
      }
    }
  ]
}